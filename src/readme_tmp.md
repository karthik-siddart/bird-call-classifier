
## first real try for a baseline
I randomly selected ?about 1000? files 5 catagories and well balanced.
Using random 70/30 split I did a baseline with a CNN.

input was 138x138 greyscale melspectrogram(?)
results as follows:
[1]: run cnn_birds.py
Using TensorFlow backend.
Found 739 images belonging to 5 classes.
Found 299 images belonging to 5 classes.
Epoch 1/10

20/20 [==============================] - 45s - loss: 4.7388 - acc: 0.2078 - val_loss: 1.6120 - val_acc: 0.2007
Epoch 2/10
20/20 [==============================] - 45s - loss: 1.5441 - acc: 0.2903 - val_loss: 1.6161 - val_acc: 0.2107
Epoch 3/10
20/20 [==============================] - 45s - loss: 1.4739 - acc: 0.3918 - val_loss: 1.6323 - val_acc: 0.2408
Epoch 4/10
20/20 [==============================] - 45s - loss: 1.4248 - acc: 0.3573 - val_loss: 1.7091 - val_acc: 0.2642
Epoch 5/10
20/20 [==============================] - 44s - loss: 1.3647 - acc: 0.4234 - val_loss: 1.6508 - val_acc: 0.2441
Epoch 6/10
20/20 [==============================] - 44s - loss: 1.3313 - acc: 0.4448 - val_loss: 1.6557 - val_acc: 0.2742
Epoch 7/10
20/20 [==============================] - 45s - loss: 1.2588 - acc: 0.4609 - val_loss: 1.5795 - val_acc: 0.2876
Epoch 8/10
20/20 [==============================] - 44s - loss: 1.1130 - acc: 0.5552 - val_loss: 1.6610 - val_acc: 0.2876
Epoch 9/10
20/20 [==============================] - 44s - loss: 1.0169 - acc: 0.6351 - val_loss: 1.6271 - val_acc: 0.3244
Epoch 10/10
20/20 [==============================] - 44s - loss: 0.9512 - acc: 0.6380 - val_loss: 1.6365 - val_acc: 0.3980

In [2]: model.evaluate_generator(X_test_gen, steps=10)
Out[2]: [1.6365334557051643, 0.39799331163482921]

In [3]: model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 136, 136, 32)      320
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 134, 134, 64)      18496
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 67, 67, 64)        0
_________________________________________________________________
dropout_1 (Dropout)          (None, 67, 67, 64)        0
_________________________________________________________________
flatten_1 (Flatten)          (None, 287296)            0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               36774016
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 5)                 645
=================================================================
Total params: 36,793,477
Trainable params: 36,793,477
Non-trainable params: 0
_________________________________________________________________

## second try after exiting ipython to be sure the model was wiped

In [1]: run cnn_birds.py
Using TensorFlow backend.
Found 739 images belonging to 5 classes.
Found 299 images belonging to 5 classes.
Epoch 1/10

20/20 [==============================] - 46s - loss: 4.9472 - acc: 0.2141 - val_loss: 1.6188 - val_acc: 0.2174
Epoch 2/10
20/20 [==============================] - 44s - loss: 1.5647 - acc: 0.2837 - val_loss: 1.6572 - val_acc: 0.2308
Epoch 3/10
20/20 [==============================] - 44s - loss: 1.4889 - acc: 0.3433 - val_loss: 1.6717 - val_acc: 0.2441
Epoch 4/10
20/20 [==============================] - 44s - loss: 1.4588 - acc: 0.3633 - val_loss: 1.6995 - val_acc: 0.2174
Epoch 5/10
20/20 [==============================] - 44s - loss: 1.3941 - acc: 0.4028 - val_loss: 1.6241 - val_acc: 0.3110
Epoch 6/10
20/20 [==============================] - 45s - loss: 1.3453 - acc: 0.4403 - val_loss: 1.6624 - val_acc: 0.2575
Epoch 7/10
20/20 [==============================] - 48s - loss: 1.2310 - acc: 0.4844 - val_loss: 1.6498 - val_acc: 0.2776
Epoch 8/10
20/20 [==============================] - 45s - loss: 1.1670 - acc: 0.5236 - val_loss: 1.6833 - val_acc: 0.2876
Epoch 9/10
20/20 [==============================] - 45s - loss: 1.0717 - acc: 0.5628 - val_loss: 1.5956 - val_acc: 0.3445
Epoch 10/10
20/20 [==============================] - 45s - loss: 0.9486 - acc: 0.6304 - val_loss: 1.5926 - val_acc: 0.3980

In [2]: model.evaluate_generator(X_test_gen, steps=10)
Out[2]: [1.5925888146046412, 0.39799331123613596]

model summary identical to above baseline accuracy: 0.39799331

===================
using log power spectrogram 138x138
In [9]: run cnn_birds.py
Found 622 images belonging to 5 classes.
Found 416 images belonging to 5 classes.
Epoch 1/10
20/20 [==============================] - 43s - loss: 3.4793 - acc: 0.2123 - val_loss: 1.6025 - val_acc: 0.2094
Epoch 2/10
20/20 [==============================] - 42s - loss: 1.5907 - acc: 0.2573 - val_loss: 1.5607 - val_acc: 0.3531
Epoch 3/10
20/20 [==============================] - 43s - loss: 1.5594 - acc: 0.3253 - val_loss: 1.5382 - val_acc: 0.2875
Epoch 4/10
20/20 [==============================] - 43s - loss: 1.4798 - acc: 0.3858 - val_loss: 1.5601 - val_acc: 0.3000
Epoch 5/10
20/20 [==============================] - 43s - loss: 1.4677 - acc: 0.3816 - val_loss: 1.4659 - val_acc: 0.3531
Epoch 6/10
20/20 [==============================] - 43s - loss: 1.3663 - acc: 0.4273 - val_loss: 1.4635 - val_acc: 0.3281
Epoch 7/10
20/20 [==============================] - 43s - loss: 1.2798 - acc: 0.4715 - val_loss: 1.3227 - val_acc: 0.4500
Epoch 8/10
20/20 [==============================] - 43s - loss: 1.1532 - acc: 0.5523 - val_loss: 1.2258 - val_acc: 0.5344
Epoch 9/10
20/20 [==============================] - 43s - loss: 0.9831 - acc: 0.6321 - val_loss: 1.2165 - val_acc: 0.5625
Epoch 10/10
20/20 [==============================] - 43s - loss: 0.8045 - acc: 0.7177 - val_loss: 1.0898 - val_acc: 0.5813

In [10]: model.evaluate_generator(X_test_gen, steps=11)
Out[10]: [1.0862427678975193, 0.57954545454545459]
In [11]: model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_5 (Conv2D)            (None, 136, 136, 32)      320
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 134, 134, 64)      18496
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 67, 67, 64)        0
_________________________________________________________________
dropout_5 (Dropout)          (None, 67, 67, 64)        0
_________________________________________________________________
flatten_3 (Flatten)          (None, 287296)            0
_________________________________________________________________
dense_5 (Dense)              (None, 128)               36774016
_________________________________________________________________
dropout_6 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_6 (Dense)              (None, 5)                 645
=================================================================
Total params: 36,793,477
Trainable params: 36,793,477
Non-trainable params: 0
_________________________________________________________________
=======================================================================
Epoch 1/10
20/20 [==============================] - 61s - loss: 1.6179 - acc: 0.2051 - val_loss: 1.6092 - val_acc: 0.2281
Epoch 2/10
20/20 [==============================] - 62s - loss: 1.6072 - acc: 0.2330 - val_loss: 1.6073 - val_acc: 0.1906
Epoch 3/10
20/20 [==============================] - 61s - loss: 1.5995 - acc: 0.2123 - val_loss: 1.5826 - val_acc: 0.2250
Epoch 4/10
20/20 [==============================] - 61s - loss: 1.6048 - acc: 0.2436 - val_loss: 1.6031 - val_acc: 0.2219
Epoch 5/10
20/20 [==============================] - 61s - loss: 1.5953 - acc: 0.2417 - val_loss: 1.5864 - val_acc: 0.3063
Epoch 6/10
20/20 [==============================] - 62s - loss: 1.5579 - acc: 0.2877 - val_loss: 1.5276 - val_acc: 0.2875
Epoch 7/10
20/20 [==============================] - 62s - loss: 1.5537 - acc: 0.3115 - val_loss: 1.5189 - val_acc: 0.3563
Epoch 8/10
20/20 [==============================] - 62s - loss: 1.5339 - acc: 0.3183 - val_loss: 1.5178 - val_acc: 0.3688
Epoch 9/10
20/20 [==============================] - 63s - loss: 1.5015 - acc: 0.3378 - val_loss: 1.4203 - val_acc: 0.4188
Epoch 10/10
20/20 [==============================] - 61s - loss: 1.4060 - acc: 0.4042 - val_loss: 1.3006 - val_acc: 0.4219

In [2]:

In [2]: model.evaluate_generator(X_test_gen, steps=11)
Out[2]: [1.3192208355123347, 0.44602272727272729]

In [3]: model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 136, 136, 32)      320
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 134, 134, 64)      18496
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 67, 67, 64)        0
_________________________________________________________________
dropout_1 (Dropout)          (None, 67, 67, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 65, 65, 128)       73856
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 32, 128)       0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 30, 30, 128)       147584
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 15, 15, 128)       0
_________________________________________________________________
dropout_3 (Dropout)          (None, 15, 15, 128)       0
_________________________________________________________________
flatten_1 (Flatten)          (None, 28800)             0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3686528
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 5)                 645
=================================================================
Total params: 3,927,429
Trainable params: 3,927,429
Non-trainable params: 0
_________________________________________________________________

In [4]:



========
read in the master mp3 names
read in the df list of data
create a label, join to audio file,
xtrain test split based on percentage
send to method to be processed and written to proper dir for image generator to flow in
==================
===================
on full data set 335xx files
00/300 [==============================] - 362s - loss: 0.8538 - acc: 0.7315 - val_loss: 1.9906 - val_acc: 0.5306
Epoch 99/100
300/300 [==============================] - 362s - loss: 0.8680 - acc: 0.7261 - val_loss: 2.2231 - val_acc: 0.5247
Epoch 100/100
300/300 [==============================] - 362s - loss: 0.8410 - acc: 0.7321 - val_loss: 2.3893 - val_acc: 0.5299

In [2]: model.evaluate_generator(X_test_gen, steps=20)
Out[2]: [2.157902216911316, 0.54531249999999998]

In [3]: model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 136, 136, 32)      320
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 134, 134, 64)      18496
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 67, 67, 64)        0
_________________________________________________________________
dropout_1 (Dropout)          (None, 67, 67, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 65, 65, 128)       73856
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 32, 128)       0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 30, 30, 128)       147584
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 15, 15, 128)       0
_________________________________________________________________
dropout_3 (Dropout)          (None, 15, 15, 128)       0
_________________________________________________________________
flatten_1 (Flatten)          (None, 28800)             0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3686528
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 40)                5160
=================================================================
Total params: 3,931,944
Trainable params: 3,931,944
Non-trainable params: 0
_________________________________________________________________


=====================================================================
central Q frequency:
log_1k_cqt_data2017112600000520171126003254_model.json


In [5]: model.evaluate_generator(X_test_gen, steps=10)
Out[5]: [1.8668826635067279, 0.55769230845646978]

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 136, 136, 32)      320
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 134, 134, 64)      18496
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 67, 67, 64)        0
_________________________________________________________________
dropout_1 (Dropout)          (None, 67, 67, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 65, 65, 128)       73856
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 32, 128)       0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 30, 30, 128)       147584
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 15, 15, 128)       0
_________________________________________________________________
dropout_3 (Dropout)          (None, 15, 15, 128)       0
_________________________________________________________________
flatten_1 (Flatten)          (None, 28800)             0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3686528
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 5)                 645
=================================================================
Total params: 3,927,429
Trainable params: 3,927,429
Non-trainable params: 0
_________________________________________________________________
======================================================================
======================================================================

used PReLU() a bit on cqt 1k 50 epochs
model.evaluate_generator(X_test_gen, steps=11)
Out[2]: [2.7332063941068427, 0.48837209440941032]
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 136, 136, 32)      320
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 134, 134, 64)      18496
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 67, 67, 64)        0
_________________________________________________________________
dropout_1 (Dropout)          (None, 67, 67, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 65, 65, 128)       73856
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 32, 128)       0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 30, 30, 128)       147584
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 15, 15, 128)       0
_________________________________________________________________
dropout_3 (Dropout)          (None, 15, 15, 128)       0
_________________________________________________________________
flatten_1 (Flatten)          (None, 28800)             0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3686528
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 5)                 645
=================================================================
Total params: 3,927,429
Trainable params: 3,927,429
Non-trainable params: 0
_________________________________________________________________
======================================================================
======================================================================
perceptually weighted log CQT:
Re-weight a CQT power spectrum, using peak power as reference
cannot save model with **** PReLU **** activation

In [12]: df_pred.to_csv('precption_cqt_predictions_test_83.csv')

In [13]: model.evaluate_generator(X_test_gen, steps=12)
Out[13]: [1.4557358483050733, 0.49999999936590805]

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 136, 136, 32)      320
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 134, 134, 64)      18496
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 67, 67, 64)        0
_________________________________________________________________
dropout_1 (Dropout)          (None, 67, 67, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 65, 65, 128)       73856
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 32, 128)       0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 30, 30, 128)       147584
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 15, 15, 128)       0
_________________________________________________________________
dropout_3 (Dropout)          (None, 15, 15, 128)       0
_________________________________________________________________
flatten_1 (Flatten)          (None, 28800)             0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3686528
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 5)                 645
=================================================================
Total params: 3,927,429
Trainable params: 3,927,429
Non-trainable params: 0
_________________________________________________________________
=================================================================
=================================================================
back to the stsf with PReLU
added 2 layers to mlp 128 each

not so great:
In [2]: model.evaluate_generator(X_test_gen, steps=10)
Out[2]: [2.6858222484588623, 0.61858974511806786]

Epoch 26/50
30/30 [==============================] - 49s - loss: 0.1290 - acc: 0.9656 - val_loss: 1.6993 - val_acc: 0.6536
Epoch 27/50
30/30 [==============================] - 49s - loss: 0.0983 - acc: 0.9698 - val_loss: 1.6916 - val_acc: 0.6691
Epoch 28/50
30/30 [==============================] - 49s - loss: 0.0373 - acc: 0.9906 - val_loss: 1.9115 - val_acc: 0.6711
Epoch 29/50
30/30 [==============================] - 50s - loss: 0.0408 - acc: 0.9855 - val_loss: 2.1107 - val_acc: 0.6678
Epoch 30/50
30/30 [==============================] - 49s - loss: 0.0320 - acc: 0.9912 - val_loss: 2.1869 - val_acc: 0.6330
Epoch 31/50
30/30 [==============================] - 49s - loss: 0.0533 - acc: 0.9833 - val_loss: 2.1244 - val_acc: 0.6410
Epoch 32/50
30/30 [==============================] - 49s - loss: 0.0505 - acc: 0.9781 - val_loss: 2.1108 - val_acc: 0.6571
Epoch 33/50
30/30 [==============================] - 49s - loss: 0.0596 - acc: 0.9823 - val_loss: 2.3822 - val_acc: 0.6324
Epoch 34/50
30/30 [==============================] - 49s - loss: 0.0362 - acc: 0.9885 - val_loss: 2.1305 - val_acc: 0.6504
Epoch 35/50
30/30 [==============================] - 49s - loss: 0.0308 - acc: 0.9885 - val_loss: 2.3853 - val_acc: 0.6624
Epoch 36/50
30/30 [==============================] - 50s - loss: 0.0469 - acc: 0.9875 - val_loss: 2.3479 - val_acc: 0.6343
Epoch 37/50
30/30 [==============================] - 49s - loss: 0.0287 - acc: 0.9912 - val_loss: 2.2791 - val_acc: 0.6424
Epoch 38/50
30/30 [==============================] - 49s - loss: 0.0426 - acc: 0.9917 - val_loss: 2.1302 - val_acc: 0.6357
Epoch 39/50
30/30 [==============================] - 50s - loss: 0.0380 - acc: 0.9865 - val_loss: 2.3563 - val_acc: 0.6424
Epoch 40/50
30/30 [==============================] - 49s - loss: 0.0277 - acc: 0.9937 - val_loss: 2.4063 - val_acc: 0.6303
Epoch 41/50
30/30 [==============================] - 49s - loss: 0.0660 - acc: 0.9818 - val_loss: 2.2373 - val_acc: 0.6223
Epoch 42/50
30/30 [==============================] - 49s - loss: 0.0756 - acc: 0.9760 - val_loss: 2.4990 - val_acc: 0.6190
Epoch 43/50
30/30 [==============================] - 49s - loss: 0.0461 - acc: 0.9885 - val_loss: 2.3204 - val_acc: 0.6397
Epoch 44/50
30/30 [==============================] - 49s - loss: 0.0245 - acc: 0.9937 - val_loss: 2.4771 - val_acc: 0.6725
Epoch 45/50
30/30 [==============================] - 49s - loss: 0.0289 - acc: 0.9917 - val_loss: 2.6225 - val_acc: 0.6364
Epoch 46/50
30/30 [==============================] - 49s - loss: 0.0557 - acc: 0.9808 - val_loss: 2.3305 - val_acc: 0.6396
Epoch 47/50
30/30 [==============================] - 49s - loss: 0.0577 - acc: 0.9829 - val_loss: 2.2713 - val_acc: 0.6384
Epoch 48/50
30/30 [==============================] - 49s - loss: 0.0796 - acc: 0.9797 - val_loss: 2.3104 - val_acc: 0.6384
Epoch 49/50
30/30 [==============================] - 49s - loss: 0.0632 - acc: 0.9771 - val_loss: 2.3923 - val_acc: 0.6197
Epoch 50/50
30/30 [==============================] - 49s - loss: 0.0556 - acc: 0.9887 - val_loss: 2.6178 - val_acc: 0.6237
_________________________________________________________________
model.summary()

Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 136, 136, 32)      320
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 134, 134, 64)      18496
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 67, 67, 64)        0
_________________________________________________________________
dropout_1 (Dropout)          (None, 67, 67, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 65, 65, 128)       73856
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 32, 128)       0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 30, 30, 128)       147584
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 15, 15, 128)       0
_________________________________________________________________
dropout_3 (Dropout)          (None, 15, 15, 128)       0
_________________________________________________________________
flatten_1 (Flatten)          (None, 28800)             0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3686528
_________________________________________________________________
dense_2 (Dense)              (None, 128)               16512
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 645
=================================================================
Total params: 3,943,941
Trainable params: 3,943,941
Non-trainable params: 0
____________________________________________________
=================================================================
=================================================================
small 1k sample with 7/3 split and 1 flat layers
30/30 [==============================] - 165s - loss: 0.0834 - acc: 0.9729 - val_loss: 1.9333 - val_acc: 0.6718
Epoch 46/50
30/30 [==============================] - 164s - loss: 0.0979 - acc: 0.9625 - val_loss: 1.6802 - val_acc: 0.6762
Epoch 47/50
30/30 [==============================] - 156s - loss: 0.0720 - acc: 0.9672 - val_loss: 1.8570 - val_acc: 0.6791
Epoch 48/50
30/30 [==============================] - 163s - loss: 0.0449 - acc: 0.9875 - val_loss: 1.7193 - val_acc: 0.7045
Epoch 49/50
30/30 [==============================] - 180s - loss: 0.0647 - acc: 0.9724 - val_loss: 1.7187 - val_acc: 0.7106
Epoch 50/50
30/30 [==============================] - 210s - loss: 0.0827 - acc: 0.9720 - val_loss: 2.0121 - val_acc: 0.6898

In [3]:

In [3]: model.evaluate_generator(X_test_gen, steps=11)
Out[3]: [2.0647702272548232, 0.6831395334975664]

df.to_csv('pred1K_1flat_prelu.csv')

=================================================================
v=================================================================
full set 33k stft with PReLU   :
model.evaluate_generator(X_test_gen, steps=320)
Out[4]: [1.9110446887090802, 0.53164062499999998]


Epoch 47/65
300/300 [==============================] - 402s - loss: 1.3286 - acc: 0.6060 - val_loss: 1.8701 - val_acc: 0.5339
Epoch 48/65
300/300 [==============================] - 403s - loss: 1.2966 - acc: 0.6039 - val_loss: 1.9042 - val_acc: 0.5072
Epoch 49/65
300/300 [==============================] - 403s - loss: 1.2729 - acc: 0.6142 - val_loss: 1.9040 - val_acc: 0.5033
Epoch 50/65
300/300 [==============================] - 402s - loss: 1.3172 - acc: 0.6036 - val_loss: 1.9235 - val_acc: 0.5202
Epoch 51/65
300/300 [==============================] - 403s - loss: 1.2669 - acc: 0.6154 - val_loss: 1.8178 - val_acc: 0.5502
Epoch 52/65
300/300 [==============================] - 404s - loss: 1.2465 - acc: 0.6165 - val_loss: 1.9522 - val_acc: 0.5163
Epoch 53/65
300/300 [==============================] - 404s - loss: 1.2617 - acc: 0.6173 - val_loss: 1.8906 - val_acc: 0.5169
Epoch 54/65
300/300 [==============================] - 403s - loss: 1.2359 - acc: 0.6258 - val_loss: 2.0182 - val_acc: 0.5111
Epoch 55/65
300/300 [==============================] - 404s - loss: 1.2430 - acc: 0.6237 - val_loss: 1.8575 - val_acc: 0.5286
Epoch 56/65
300/300 [==============================] - 403s - loss: 1.1985 - acc: 0.6349 - val_loss: 1.9331 - val_acc: 0.5358
Epoch 57/65
300/300 [==============================] - 402s - loss: 1.1892 - acc: 0.6315 - val_loss: 1.9900 - val_acc: 0.5371
Epoch 58/65
300/300 [==============================] - 403s - loss: 1.1791 - acc: 0.6378 - val_loss: 1.8418 - val_acc: 0.5469
Epoch 59/65
300/300 [==============================] - 402s - loss: 1.1797 - acc: 0.6370 - val_loss: 1.8826 - val_acc: 0.5352
Epoch 60/65
300/300 [==============================] - 403s - loss: 1.1480 - acc: 0.6500 - val_loss: 1.9137 - val_acc: 0.5273
Epoch 61/65
300/300 [==============================] - 402s - loss: 1.1837 - acc: 0.6371 - val_loss: 2.0155 - val_acc: 0.5098
Epoch 62/65
300/300 [==============================] - 401s - loss: 1.1574 - acc: 0.6472 - val_loss: 2.0130 - val_acc: 0.5306
Epoch 63/65
300/300 [==============================] - 402s - loss: 1.1530 - acc: 0.6402 - val_loss: 2.0172 - val_acc: 0.5111
Epoch 64/65
300/300 [==============================] - 403s - loss: 1.1190 - acc: 0.6515 - val_loss: 1.8847 - val_acc: 0.5430
Epoch 65/65
300/300 [==============================] - 401s - loss: 1.1441 - acc: 0.6564 - val_loss: 1.8338 - val_acc: 0.5547
In [2]: model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 136, 136, 32)      320
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 134, 134, 64)      18496
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 67, 67, 64)        0
_________________________________________________________________
dropout_1 (Dropout)          (None, 67, 67, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 65, 65, 128)       73856
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 32, 128)       0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 30, 30, 128)       147584
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 15, 15, 128)       0
_________________________________________________________________
dropout_3 (Dropout)          (None, 15, 15, 128)       0
_________________________________________________________________
flatten_1 (Flatten)          (None, 28800)             0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3686528
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 40)                5160
=================================================================
Total params: 3,931,944
Trainable params: 3,931,944
Non-trainable params: 0
_________________________________________________________________


==================================================================================
==================================================================================

complex cnn with 1k data at 224x244 for 60sec
In [5]: model.evaluate_generator(X_test_gen, steps=10)
Out[5]: [2.9035682494823751, 0.46153846230262363]


Epoch 47/50
30/30 [==============================] - 25s - loss: 0.9522 - acc: 0.6863 - val_loss: 4.2686 - val_acc: 0.3810
Epoch 48/50
30/30 [==============================] - 25s - loss: 0.8282 - acc: 0.7351 - val_loss: 3.3978 - val_acc: 0.2614
Epoch 49/50
30/30 [==============================] - 25s - loss: 0.8806 - acc: 0.7132 - val_loss: 3.5638 - val_acc: 0.3870
Epoch 50/50
30/30 [==============================] - 24s - loss: 0.8346 - acc: 0.7164 - val_loss: 2.8690 - val_acc: 0.4621


In [2]: model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 54, 54, 96)        11712
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 26, 26, 96)        0
_________________________________________________________________
batch_normalization_1 (Batch (None, 26, 26, 96)        384
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 22, 22, 256)       614656
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 10, 10, 256)       0
_________________________________________________________________
batch_normalization_2 (Batch (None, 10, 10, 256)       1024
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 6, 6, 384)         885120
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 4, 4, 384)         1327488
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 1, 1, 384)         0
_________________________________________________________________
batch_normalization_3 (Batch (None, 1, 1, 384)         1536
_________________________________________________________________
flatten_1 (Flatten)          (None, 384)               0
_________________________________________________________________
dense_1 (Dense)              (None, 4096)              1576960
_________________________________________________________________
dropout_1 (Dropout)          (None, 4096)              0
_________________________________________________________________
dense_2 (Dense)              (None, 4096)              16781312
_________________________________________________________________
dropout_2 (Dropout)          (None, 4096)              0
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 20485
=================================================================
Total params: 21,810,757
Trainable params: 21,809,285
Non-trainable params: 1,472
_________________________________________________________________

==================================================================================
==================================================================================
using alex_net with 224x224 60sec sr=22050 1k STSF sample size
--crappy
Epoch 40/50
30/30 [==============================] - 62s - loss: 1.7193 - acc: 0.3742 - val_loss: 2.5423 - val_acc: 0.1832
Epoch 41/50
30/30 [==============================] - 63s - loss: 1.6332 - acc: 0.4081 - val_loss: 3.4627 - val_acc: 0.2068
Epoch 42/50
30/30 [==============================] - 62s - loss: 1.8104 - acc: 0.3625 - val_loss: 2.4200 - val_acc: 0.3021
Epoch 43/50
30/30 [==============================] - 62s - loss: 1.7457 - acc: 0.4179 - val_loss: 2.2909 - val_acc: 0.2226
Epoch 44/50
30/30 [==============================] - 62s - loss: 1.8001 - acc: 0.3798 - val_loss: 2.1640 - val_acc: 0.2487
Epoch 45/50
30/30 [==============================] - 62s - loss: 1.8274 - acc: 0.3903 - val_loss: 2.0340 - val_acc: 0.3095
Epoch 46/50
30/30 [==============================] - 62s - loss: 1.6960 - acc: 0.3862 - val_loss: 2.5007 - val_acc: 0.2434
Epoch 47/50
30/30 [==============================] - 68s - loss: 1.6175 - acc: 0.3868 - val_loss: 2.3091 - val_acc: 0.2874
Epoch 48/50
30/30 [==============================] - 72s - loss: 1.7628 - acc: 0.3626 - val_loss: 2.9278 - val_acc: 0.2333
Epoch 49/50
30/30 [==============================] - 72s - loss: 1.6085 - acc: 0.3776 - val_loss: 2.8797 - val_acc: 0.2286
Epoch 50/50
30/30 [==============================] - 65s - loss: 1.5037 - acc: 0.4215 - val_loss: 3.5948 - val_acc: 0.2781

In [4]: model.evaluate_generator(X_test_gen, steps=10)
Out[4]: [3.6104505306635146, 0.27884615461031598]

=========================================================================================================
=========================================================================================================
samples 1k at 224x224 and sr=44.1 for 30sec with stft
In [2]: model.evaluate_generator(X_test_gen, steps=10)
Out[2]: [1.01009935599107, 0.66666666666666663]
--slightly less accurate than 138x138 with sr=1/2 of this sr

Epoch 28/50
30/30 [==============================] - 119s - loss: 1.2670 - acc: 0.4424 - val_loss: 1.3084 - val_acc: 0.4572
Epoch 29/50
30/30 [==============================] - 118s - loss: 1.2236 - acc: 0.4603 - val_loss: 2.9294 - val_acc: 0.3148
Epoch 30/50
30/30 [==============================] - 116s - loss: 1.2167 - acc: 0.4866 - val_loss: 1.2147 - val_acc: 0.5140
Epoch 31/50
30/30 [==============================] - 117s - loss: 1.1786 - acc: 0.5097 - val_loss: 1.9226 - val_acc: 0.3544
Epoch 32/50
30/30 [==============================] - 119s - loss: 1.1402 - acc: 0.5432 - val_loss: 1.6174 - val_acc: 0.4258
Epoch 33/50
30/30 [==============================] - 117s - loss: 1.1164 - acc: 0.5191 - val_loss: 1.1728 - val_acc: 0.5548
Epoch 34/50
30/30 [==============================] - 117s - loss: 1.1237 - acc: 0.5416 - val_loss: 1.4648 - val_acc: 0.4418
Epoch 35/50
30/30 [==============================] - 117s - loss: 1.0569 - acc: 0.5591 - val_loss: 1.3018 - val_acc: 0.5167
Epoch 36/50
30/30 [==============================] - 117s - loss: 1.0977 - acc: 0.5551 - val_loss: 1.8180 - val_acc: 0.4255
Epoch 37/50
30/30 [==============================] - 118s - loss: 1.0687 - acc: 0.5687 - val_loss: 3.4631 - val_acc: 0.3536
Epoch 38/50
30/30 [==============================] - 117s - loss: 1.0337 - acc: 0.5511 - val_loss: 1.0748 - val_acc: 0.5869
Epoch 39/50
30/30 [==============================] - 118s - loss: 0.9776 - acc: 0.5728 - val_loss: 1.0246 - val_acc: 0.6210
Epoch 40/50
30/30 [==============================] - 116s - loss: 1.0156 - acc: 0.5823 - val_loss: 1.2217 - val_acc: 0.6176
Epoch 41/50
30/30 [==============================] - 118s - loss: 0.9369 - acc: 0.5948 - val_loss: 1.3432 - val_acc: 0.6117
Epoch 42/50
30/30 [==============================] - 118s - loss: 0.9053 - acc: 0.6248 - val_loss: 1.2918 - val_acc: 0.5154
Epoch 43/50
30/30 [==============================] - 117s - loss: 0.8708 - acc: 0.6173 - val_loss: 1.2561 - val_acc: 0.5508
Epoch 44/50
30/30 [==============================] - 119s - loss: 0.8741 - acc: 0.6323 - val_loss: 1.0887 - val_acc: 0.5983
Epoch 45/50
30/30 [==============================] - 118s - loss: 0.8095 - acc: 0.6577 - val_loss: 1.1099 - val_acc: 0.6243
Epoch 46/50
30/30 [==============================] - 117s - loss: 0.7387 - acc: 0.6891 - val_loss: 1.0943 - val_acc: 0.6549
Epoch 47/50
30/30 [==============================] - 118s - loss: 0.7071 - acc: 0.6945 - val_loss: 1.1291 - val_acc: 0.6070
Epoch 48/50
30/30 [==============================] - 118s - loss: 0.7037 - acc: 0.7029 - val_loss: 0.9908 - val_acc: 0.6491
Epoch 49/50
30/30 [==============================] - 118s - loss: 0.6706 - acc: 0.7226 - val_loss: 1.1303 - val_acc: 0.6350
Epoch 50/50
30/30 [==============================] - 117s - loss: 0.6585 - acc: 0.7154 - val_loss: 1.0073 - val_acc: 0.6644

indices:
{
 'bewicks-wren-thryomanes-bewickii': 0,
 'european-greenfinch-chloris-chloris': 1,
 'fox-sparrow-passerella-iliaca': 2,
 'swainsons-thrush-catharus-ustulatus': 3,
 'tree-pipit-anthus-trivialis': 4}

In [9]: model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 222, 222, 32)      320
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 220, 220, 64)      18496
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 110, 110, 64)      0
_________________________________________________________________
dropout_1 (Dropout)          (None, 110, 110, 64)      0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 108, 108, 128)     73856
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 54, 54, 128)       0
_________________________________________________________________
dropout_2 (Dropout)          (None, 54, 54, 128)       0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 52, 52, 128)       147584
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 26, 26, 128)       0
_________________________________________________________________
batch_normalization_1 (Batch (None, 26, 26, 128)       512
_________________________________________________________________
dropout_3 (Dropout)          (None, 26, 26, 128)       0
_________________________________________________________________
flatten_1 (Flatten)          (None, 86528)             0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               11075712
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 5)                 645
=================================================================
Total params: 11,317,125
Trainable params: 11,316,869
Non-trainable params: 256
_________________________________________________________________
=====================================================================
=====================================================================

using down sample to 11025 for 30 at 128x128 stft hop len=32
cnn-> changed to use l2 regularization with cnn PReLU layers added properly now

In [3]: model.evaluate_generator(X_test_gen, steps=10)
Out[3]: [2.0442244639763465, 0.58653846001013732]

(I missed the rolling output verbose-1)
indices: {'bewicks-wren-thryomanes-bewickii': 0,
 'european-greenfinch-chloris-chloris': 1,
 'fox-sparrow-passerella-iliaca': 2,
 'swainsons-thrush-catharus-ustulatus': 3,
 'tree-pipit-anthus-trivialis': 4}

 predictions: img_data_1k_138x138_sr11025_hoplen32_30sec_stft.csv
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 222, 222, 32)      320
_________________________________________________________________
p_re_lu_1 (PReLU)            (None, 222, 222, 32)      1577088
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 220, 220, 64)      18496
_________________________________________________________________
p_re_lu_2 (PReLU)            (None, 220, 220, 64)      3097600
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 110, 110, 64)      0
_________________________________________________________________
dropout_1 (Dropout)          (None, 110, 110, 64)      0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 108, 108, 128)     73856
_________________________________________________________________
p_re_lu_3 (PReLU)            (None, 108, 108, 128)     1492992
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 54, 54, 128)       0
_________________________________________________________________
dropout_2 (Dropout)          (None, 54, 54, 128)       0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 52, 52, 128)       147584
_________________________________________________________________
p_re_lu_4 (PReLU)            (None, 52, 52, 128)       346112
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 26, 26, 128)       0
_________________________________________________________________
batch_normalization_1 (Batch (None, 26, 26, 128)       512
_________________________________________________________________
dropout_3 (Dropout)          (None, 26, 26, 128)       0
_________________________________________________________________
flatten_1 (Flatten)          (None, 86528)             0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               11075712
_________________________________________________________________
p_re_lu_5 (PReLU)            (None, 128)               128
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 5)                 645
_________________________________________________________________
activation_1 (Activation)    (None, 5)                 0
=================================================================
Total params: 17,831,045
Trainable params: 17,830,789
Non-trainable params: 256
_________________________________________________________________

=================================================================
=================================================================
imgdata_1k_sr22k_30sec_128x128_melspeclog

didn't work at all.....
had 224 x 224 set in cnn

=================================================================
=================================================================
with 33k S_stft  with 22050 sr and 30sec db spectrogram  
In [2]: model.evaluate_generator(X_test_gen, 30)
Out[2]: [1.5144340813159942, 0.63854166666666667]
p_re_lu_3 (PReLU)            (None, 65, 65, 128)       540800
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 32, 128)       0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 30, 30, 128)       147584
_________________________________________________________________
p_re_lu_4 (PReLU)            (None, 30, 30, 128)       115200
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 15, 15, 128)       0
_________________________________________________________________
batch_normalization_1 (Batch (None, 15, 15, 128)       512
_________________________________________________________________
dropout_3 (Dropout)          (None, 15, 15, 128)       0
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 13, 13, 128)       147584
_________________________________________________________________
p_re_lu_5 (PReLU)            (None, 13, 13, 128)       21632
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0
_________________________________________________________________
batch_normalization_2 (Batch (None, 6, 6, 128)         512
_________________________________________________________________
dropout_4 (Dropout)          (None, 6, 6, 128)         0
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 4, 4, 128)         147584
_________________________________________________________________
p_re_lu_6 (PReLU)            (None, 4, 4, 128)         2048
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 2, 2, 128)         0
_________________________________________________________________
batch_normalization_3 (Batch (None, 2, 2, 128)         512
_________________________________________________________________
dropout_5 (Dropout)          (None, 2, 2, 128)         0
_________________________________________________________________
flatten_1 (Flatten)          (None, 512)               0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               65664
_________________________________________________________________
p_re_lu_7 (PReLU)            (None, 128)               128
_________________________________________________________________
dropout_6 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 40)                5160
_________________________________________________________________
activation_1 (Activation)    (None, 40)                0
=================================================================
Total params: 3,028,648
Trainable params: 3,027,880
Non-trainable params: 768

00/300 [==============================] - 430s - loss: 1.4396 - acc: 0.6294 - val_loss: 1.5265 - val_acc: 0.6209
Epoch 49/60
300/300 [==============================] - 429s - loss: 1.3898 - acc: 0.6432 - val_loss: 1.3556 - val_acc: 0.6600
Epoch 50/60
300/300 [==============================] - 430s - loss: 1.3915 - acc: 0.6399 - val_loss: 1.4851 - val_acc: 0.6395
Epoch 51/60
300/300 [==============================] - 431s - loss: 1.4032 - acc: 0.6328 - val_loss: 1.4479 - val_acc: 0.6366
Epoch 52/60
300/300 [==============================] - 431s - loss: 1.3250 - acc: 0.6584 - val_loss: 1.4813 - val_acc: 0.6384
Epoch 53/60
300/300 [==============================] - 431s - loss: 1.3661 - acc: 0.6480 - val_loss: 1.3984 - val_acc: 0.6575
Epoch 54/60
300/300 [==============================] - 432s - loss: 1.3646 - acc: 0.6498 - val_loss: 1.4776 - val_acc: 0.6451
Epoch 55/60
300/300 [==============================] - 430s - loss: 1.3380 - acc: 0.6542 - val_loss: 1.4415 - val_acc: 0.6494
Epoch 56/60
300/300 [==============================] - 430s - loss: 1.3518 - acc: 0.6565 - val_loss: 1.4406 - val_acc: 0.6406
Epoch 57/60
300/300 [==============================] - 431s - loss: 1.3179 - acc: 0.6570 - val_loss: 1.4872 - val_acc: 0.6434
Epoch 58/60
300/300 [==============================] - 430s - loss: 1.3252 - acc: 0.6604 - val_loss: 1.4570 - val_acc: 0.6338
Epoch 59/60
300/300 [==============================] - 431s - loss: 1.3010 - acc: 0.6671 - val_loss: 1.4418 - val_acc: 0.6466
Epoch 60/60
300/300 [==============================] - 431s - loss: 1.3087 - acc: 0.6666 - val_loss: 1.5269 - val_acc: 0.6238

class_indices:
{'american-robin-turdus-migratorius': 0,
 'barn-swallow-hirundo-rustica': 1,
 'bewicks-wren-thryomanes-bewickii': 2,
 'black-headed-gull-chroicocephalus-ridibundus': 3,
 'blackish-tapaculo-scytalopus-latrans': 4,
 'bluethroat-luscinia-svecica': 5,
 'brown-crested-flycatcher-myiarchus-tyrannulus': 6,
 'common-blackbird-turdus-merula': 7,
 'common-chaffinch-fringilla-coelebs': 8,
 'common-cuckoo-cuculus-canorus': 9,
 'common-reed-bunting-emberiza-schoeniclus': 10,
 'common-starling-sturnus-vulgaris': 11,
 'eurasian-bullfinch-pyrrhula-pyrrhula': 12,
 'eurasian-skylark-alauda-arvensis': 13,
 'eurasian-tree-sparrow-passer-montanus': 14,
 'european-goldfinch-carduelis-carduelis': 15,
 'european-greenfinch-chloris-chloris': 16,
 'fieldfare-turdus-pilaris': 17,
 'fox-sparrow-passerella-iliaca': 18,
 'great-spotted-woodpecker-dendrocopos-major': 19,
 'great-tit-parus-major': 20,
 'grey-breasted-wood-wren-henicorhina-leucophrys': 21,
 'house-sparrow-passer-domesticus': 22,
 'house-wren-troglodytes-aedon': 23,
 'lesser-whitethroat-sylvia-curruca': 24,
 'northern-raven-corvus-corax': 25,
 'red-crossbill-loxia-curvirostra': 26,
 'red-winged-blackbird-agelaius-phoeniceus': 27,
 'redwing-turdus-iliacus': 28,
 'rufous-browed-peppershrike-cyclarhis-gujanensis': 29,
 'rufous-collared-sparrow-zonotrichia-capensis': 30,
 'sedge-warbler-acrocephalus-schoenobaenus': 31,
 'song-sparrow-melospiza-melodia': 32,
 'song-thrush-turdus-philomelos': 33,
 'spotted-towhee-pipilo-maculatus': 34,
 'swainsons-thrush-catharus-ustulatus': 35,
 'tree-pipit-anthus-trivialis': 36,
 'white-wagtail-motacilla-alba': 37,
 'willow-warbler-phylloscopus-trochilus': 38,
 'wood-warbler-phylloscopus-sibilatrix': 39}
